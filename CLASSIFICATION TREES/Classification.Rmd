---
title: "Win Prediction"
output:
  html_document:
    df_print: paged
---

We will test whether certain stats can help predict whether a team will win. The stats we will be using are the field goal percentage, free throw percentage, three-pointer percentage, assists, and rebounds of each team.

Our target feature will be whether or not the home team wins when these stats are taken into account.

First we will load the libraries we will be using. We will be using the C50 library for our classification model.

```{r}
library(C50)
library(caret)
library(gmodels)
library(pROC)
```
Now we will load the data, select our features, and normalize the data. We will also set our variables for how much data we will use to train the model, and how much data the model is tested on. We will also factorize whether the home team wins or not.
```{r}
# the file we will be loading
file <- read.csv("games.csv", header=TRUE, stringsAsFactors = FALSE)

# subset of file with columns that will actually be used, and are complete cases
all_data <- file[complete.cases(file),c("FG_PCT_home","FT_PCT_home","FG3_PCT_home","AST_home",
                                  "REB_home","HOME_TEAM_WINS","PTS_home","PTS_away",
                                  "FG_PCT_away","FT_PCT_away","FG3_PCT_away",	
                                  "AST_away",	"REB_away")]

#test all cases complete
sum(complete.cases(all_data))
sum(is.na(all_data))

#factorize home team
all_data$HOME_TEAM_WINS<-factor(all_data$HOME_TEAM_WINS,levels=c(0,1),labels=c("W","L"))

train_num = 17500
test_num = 2500
total=train_num+test_num

#create a normlized version of the data.
n_data <- all_data[ 1:total , c("FG_PCT_home","FT_PCT_home","FG3_PCT_home","AST_home",
                                  "REB_home",
                                  "FG_PCT_away","FT_PCT_away","FG3_PCT_away",	
                                  "AST_away",	"REB_away")]

summary(n_data)

normalize <- function(x) {
    return ((x - min(x,na.rm = TRUE)) /  (max(x,na.rm = TRUE) - min(x,na.rm = TRUE)))
}

n_data <- as.data.frame(lapply(n_data, normalize))

summary(n_data)

```
Noting from above, we have 22945 complete cases in the data set, and no NA's, also the data was normalized correctly.

Now we will segment the data between what we will train it on, and what we will test it on.
```{r paged.print=TRUE}
#segment training data
train_data <- n_data[ (1:train_num) , ]
train_labels <- all_data$HOME_TEAM_WINS[ (1:train_num) ]

#segment testing data
test_data <- n_data[ (train_num + 1) : (train_num+test_num), ]
test_labels <- all_data$HOME_TEAM_WINS[ (train_num+1) : (train_num+test_num)]
```
Now we will now train a subset of the data on the model. And also take a look at the statistics.
```{r}
#train model
class_model <- C5.0(train_data, train_labels, winnow=FALSE, seed = 2957)

#make predictions
pred_labels <- predict(class_model, test_data )

#model info
class_model

CrossTable(test_labels, pred_labels,
             prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
             dnn = c('actual default', 'predicted default'))

confusionMatrix(pred_labels,
    test_labels, positive = "W")
```
Our first model came out with a decent success rate of 79.44%.Our Kappa value has only moderate agreement at 57.49%.

We will now try to improve the model by boosting. We will do this by setting it to run 100 trials
```{r paged.print=TRUE}

#train model + boosted
class_model <- C5.0(train_data, train_labels, winnow=FALSE, seed= 2957,trials=100)

#make predictions
pred_labels <- predict(class_model, test_data )

#model info
class_model

CrossTable(test_labels, pred_labels,
             prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
             dnn = c('actual default', 'predicted default'))

confusionMatrix(pred_labels,
    test_labels, positive = "W")

```
We were able to increase our accuracty to 83.56%, and also our Kappa value went up to a better agreement value as well

We will try boosting with rules to see how it affects the results
 
```{r}
#train model + boosted + rules
class_model <- C5.0(train_data, train_labels, winnow=FALSE, seed= 2957,trials=100, rules=TRUE)

#make predictions
pred_labels <- predict(class_model, test_data )

#model info
class_model

CrossTable(test_labels, pred_labels,
             prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
             dnn = c('actual default', 'predicted default'))

confusionMatrix(pred_labels,
    test_labels, positive = "W")

```
Boosting and using rules gave us an accuracy of 84%, our kappa value also went up slightly. This final model seems to be a decent model for predicting whether or not a home team will win based on field goal percentage, free throw percentage, three-pointer percentage, assists, and rebounds of each team. It shows that the better their stats are, the better chance they have for winning their home games.


