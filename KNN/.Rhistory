#LOAD DATA AND LIBRARIES
#data set
games<-read.csv("nba-games/games.csv", header=FALSE, stringsAsFactors = FALSE)
#LOAD DATA AND LIBRARIES
#data set
games<-read.csv("games.csv", header=FALSE, stringsAsFactors = FALSE)
#libraries
library(class)
library(gmodels)
library(Amelia)
#LOAD DATA AND LIBRARIES
#data set
games<-read.csv("games.csv", header=FALSE, stringsAsFactors = FALSE)
#libraries
library(class)
library(gmodels)
library(Amelia)
#FIX DATA
#set column names to the first row of data
colnames(games)<-games[1, ]
#get rid of unneeded columns
games$GAME_DATE_EST <- NULL
games$GAME_STATUS_TEXT <- NULL
games$HOME_TEAM_ID <-NULL
games$VISITOR_TEAM_ID <- NULL
games$SEASON <- NULL
games$TEAM_ID_home <- NULL
games$TEAM_ID_away <- NULL
games$GAME_ID <- NULL
games$PTS_away <- NULL
games$PTS_home <- NULL
#factor data based on whether home team wins
games$HOME_TEAM_WINS<-factor(games$HOME_TEAM_WINS,levels=c(0,1),labels=c("W","L"))
#convert data from character to numeric
games_data<-as.data.frame(apply(games[1:10],2,as.numeric))
#get rid of NA rows from target labels
games_target_labels<-games[complete.cases(games_data),11]
#get rid of NA from data
games_data = games_data[complete.cases(games_data), ]
g2 <- games_data
g2['HOME_TEAM_WINS'] <- games_target_labels
#create normalization function
normalize<-function(x){
return((x-min(x,na.rm=TRUE))/(max(x,na.rm=TRUE)-min(x,na.rm=TRUE)))
}
#normalize from game data
games_n<-as.data.frame(lapply(games_data[1:10],normalize))
#test if there is missing data
missmap(games_n, main = "Missing values vs observed")
#seperate training from testing data
games_train<-games_n[1:18400, ]
games_test<-games_n[18401:22945, ]
#seperate training from testing labels
games_train_labels<-games_target_labels[1:18400]
games_test_labels<-games_target_labels[18401:22945]
#RUN KNN TESTS
games_test_pred<-knn(train=games_train,test=games_test,cl=games_train_labels,k=51)
CrossTable(x=games_test_labels,y=games_test_pred,prop.chisq = FALSE)
#improving knn model performance
#z-score
games_z<-as.data.frame(scale(games_data[1:10]))
#summary(games_z)
z_train<-games_z[1:18400, ]
z_test<-games_z[18401:22945, ]
#seperate training from testing labels
z_train_labels<-games_target_labels[1:18400]
z_test_labels<-games_target_labels[18401:22945]
z_test_pred<-knn(train=z_train,test=z_test,cl=z_train_labels,k=51)
CrossTable(x=z_test_labels,y=z_test_pred,prop.chisq = FALSE)
z_test_pred<-knn(train=z_train,test=z_test,cl=z_train_labels,k=300)
CrossTable(x=z_test_labels,y=z_test_pred,prop.chisq = FALSE)
knitr::opts_chunk$set(echo = TRUE)
```
#LOAD DATA AND LIBRARIES
#libraries
library(class)
library(gmodels)
library(Amelia)
library(ISLR)
library(caret)
library(readxl)
library(pROC)
library(lattice)
library(ggplot2)
library(dplyr)
library(e1071)
library(corrplot)
library(kknn)
library(ggplot2)
library(multiROC)
library(MLeval)
library(AppliedPredictiveModeling)
library(corrplot)
library(Hmisc)
library(dplyr)
library( ggfortify)
library (magrittr)
library (car)
library (broom)
library (psych)
# GET SPECIFIC DATA
file <- 0 # the file we will be loading
all_data <- 0 # subset of file with columns that will actually be used,
# and are complete cases + win_difference
home_stats <- 0 # subset of all_data containing only home team stats (except points)
away_stats <- 0 # subset of all_data containing only away team stats (except points)
win_difference <- 0 # home teams score - away team score
home_team_wins <- 0 # basically a binary of win_difference (factored)
file <- read.csv("games.csv", header=TRUE, stringsAsFactors = FALSE) #load data
all_data <- file[complete.cases(c("FG_PCT_home","FT_PCT_home","FG3_PCT_home","AST_home",
"REB_home","HOME_TEAM_WINS","PTS_home","PTS_away",
"FG_PCT_away","FT_PCT_away","FG3_PCT_away",
"AST_away",	"REB_away")), ]
all_data$win_difference=(all_data$PTS_home-all_data$PTS_away)
home_stats <- all_data[c("FG_PCT_home","FT_PCT_home","FG3_PCT_home","AST_home","REB_home")]
away_stats <- all_data[c("FG_PCT_away","FT_PCT_away","FG3_PCT_away","AST_away","REB_away")]
win_difference <- all_data$win_difference
home_team_wins <- all_data$HOME_TEAM_WINS
all_data$HOME_TEAM_WINS<-factor(all_data$HOME_TEAM_WINS,levels=c(0,1),labels=c("W","L"))
lm_test_1 <- 0 # lm model test using home_stats and win difference
lm_test_2 <- 0 # lm model test using home_stats and win difference and home_team_wins
lm_test_3 <- 0 # lm model test using home_stats and away stats and win difference and
# home team wins
lm_test_4 <- 0 # lm model test using home_stats and away stats
lm_test_1 <- lm(win_difference ~ . ,data=cbind(home_stats,win_difference))
lm_test_2 <- lm(win_difference ~ . ,data=cbind(home_stats,win_difference,home_team_wins))
lm_test_3 <- lm(win_difference ~ . ,data=cbind(home_stats, away_stats, win_difference,
home_team_wins))
lm_test_4 <- lm(win_difference ~ . ,data=cbind(home_stats, away_stats, win_difference))
summary (lm_test_1)
summary (lm_test_2)
summary (lm_test_3) #lm_test_3 seems to be the best model to manually come up with
summary (lm_test_4)
step_model <- 0 #uses AIC to check for a better model
step_model <- MASS::stepAIC(lm_test_3, direction="both", trace=FALSE)
summary (step_model)
step_model.diagnostics <- augment(step_model)
head(step_model.diagnostics)
lm_test_3$call
step_model$call
vif(step_model) %>%
knitr::kable()
# Diagnostic Plots:
#ceresPlots(step_model)
#ggplot(step_model.diagnostics, aes(win_difference, FG_PCT_home)) + geom_point() + stat_smooth(method = lm, se = FALSE) + geom_segment(aes(xend = win_difference, yend = .fitted), color = "red", size = 0.3)
autoplot( step_model)
#plot(step_model, 4)
# Residuals vs Leverage
#plot(step_model, 5)
pairs(all_data[c("FG_PCT_home","FT_PCT_home","FG3_PCT_home","AST_home","REB_home","win_difference","HOME_TEAM_WINS")])
pairs.panels(all_data[c("FG_PCT_home","FT_PCT_home","FG3_PCT_home","AST_home","REB_home","win_difference","HOME_TEAM_WINS")])
new_data <- 0 # new data frame to try to create a model from
new_data <- cbind(home_stats, away_stats, win_difference,home_team_wins)
new_data$FG_PCT_home2 <-new_data$FG_PCT_home^2
new_data$FG_PCT_away2 <-new_data$FG_PCT_home^2
new_data$FG50_home <- ifelse(new_data$FG_PCT_home >= .5, 1, 0)
new_data$FG50_away <- ifelse(new_data$FG_PCT_away >= .5, 1, 0)
reg_model_2 <- 0 # testing a new model
reg_model_2 <- lm(win_difference ~ ., data = new_data)
summary (reg_model_2)
step_model_2 <- MASS::stepAIC(reg_model_2, direction="both", trace=FALSE)
summary (step_model_2)
